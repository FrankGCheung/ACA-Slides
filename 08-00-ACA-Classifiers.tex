% move all configuration stuff into includes file so we can focus on the content
\input{include/common}
\input{include/titledef}
\input{include/definitions}


\subtitle{Module 8.0: Classifiers}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
    % generate title page
	\input{include/titlepage}

    \section[overview]{lecture overview}
        \begin{frame}{introduction}{overview}
            \begin{block}{corresponding textbook section}
                    \href{http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6331125}{Chapter 8: Musical Genre, Similarity, and Mood} (pp.~155)
            \end{block}

            \begin{itemize}
                \item   \textbf{lecture content}
                    \begin{itemize}
                        \item   training set and test set
                        \item   intuitive intro to machine learning
                        \item   classifier examples
                    \end{itemize}
                \bigskip
                \item<2->   \textbf{learning objectives}
                    \begin{itemize}
                        \item   describe the basic principles and challenges of data-driven machine learning approaches
                        \item   implement a kNN classifier in Matlab
                    \end{itemize}
            \end{itemize}
            \inserticon{directions}
        \end{frame}

    \section[intro]{introduction}
        \begin{frame}{classification}{machine learning}
            \begin{itemize}
                \item   computer runs a 'generic' program
                \item   adapts parameters to training data
                \bigskip
                \item[$\Rightarrow$] \textbf{data driven} approach
                
                \bigskip
                \item<2->[] data and its representation defines much of the outcome
                    \begin{itemize}
                        \item   \textit{validity}: is data representative sample and do features focus on important characteristics
                        \item   \textit{reliability}: does data lead to accurate and consistent results
                        \item   \textit{reproducibility}: will multiple runs result in similar results
                    \end{itemize}
            \end{itemize}
        \end{frame}
        \begin{frame}{classification}{general steps}
            \begin{enumerate}
                \item	\textbf{define training set}: annotated results
                \smallskip
                \item<2->	\textbf{normalize} training set
                \smallskip
                \item<3->	\textbf{train} classifier
                \smallskip
                \item<4->	\textbf{evaluate} classifier with test (or validation) set
                \smallskip
                \item<5->	(\textbf{adjust} classifier settings, return to 4.)
            \end{enumerate}
        \end{frame}
        
    \section{classification}
        \begin{frame}{classification}{rules of thumb}
            \vspace{-3mm}
            \begin{itemize}
                \item   \textbf{training set}
                    \begin{itemize}
                        \item	training set size vs.\ number of features
                            \begin{itemize}
                                \item	training set too small,% $\Rightarrow$ \textit{overfitting}
                                feature number too large $\Rightarrow$ \textit{overfitting}
                            \end{itemize}
                        \item<1->	training set \textbf{too noisy} $\Rightarrow$ \textit{underfitting}
                        \item<1->	training set \textbf{not representative} $\Rightarrow$ \textit{bad classification performance}
                    \end{itemize}
                \smallskip
                \item<2->   \textbf{classifier}
                    \begin{itemize}
                        \item<2->   classifier too complex $\Rightarrow$ \textit{overfitting}
                        \item<2->	\textbf{poor classifier} $\Rightarrow$ \textit{bad classification performance}
                            \begin{itemize}
                                \item[$\rightarrow$]	different classifier
                            \end{itemize}
                    \end{itemize}
                \smallskip
                \item<3->   \textbf{features}
                    \begin{itemize}
                        \item<3->	\textbf{poor features} $\Rightarrow$ \textit{bad classification performance}
                            \begin{itemize}
                                \item[$\rightarrow$]	new, better features
                            \end{itemize}
                        \item<3->	features \textbf{not normalized} $\Rightarrow$ possibly \textit{bad classification performance}
                            \begin{itemize}
                                \item	feature distribution (range, mean, symmetry)
                            \end{itemize}
                    \end{itemize}
            \end{itemize}
        \end{frame}
        \begin{frame}{musical genre classification}{classifier: evaluation}
            \begin{itemize}
                \item	define \textbf{test set} for evaluation
                    \begin{itemize}
                        \item	test set \textit{different} from training set
                        \item	otherwise, same requirements
                    \end{itemize}
                
                \bigskip
                \item<2->	example: \textbf{$N$-fold cross validation}
                    \begin{enumerate}
                        \item<2->	split training set into $N$ parts (randomly, but preferably identical number per class)
                        \item<3->	select one part as test set
                        \item<4->	train the classifier with all observations from remaining $N-1$ parts
                        \item<5->	compute the classification rate for the test set
                        \item<6->	repeat until all $N$ parts have been tested
                        \item<7->	overall result: \textit{average} classification rate
                    \end{enumerate}
            \end{itemize}
        \end{frame}
        
     \section{classifier examples}
        \begin{frame}{musical genre classification}{classifier: kNN}
            \begin{columns}
                \column{.6\linewidth} 
                    \begin{itemize}
                        \item	\textbf{training}: extract reference vectors from training set (keep class labels)
                        \item<2->	\textbf{classification}: extract test vector and set class to majority of $k$ nearest reference vectors
                        \bigskip
                        \item<6->	\textbf{classifier data}: all training vectors
                    \end{itemize}
                \column{.4\linewidth} 
                    \only<1,6>{\begin{figure}\includegraphics[width=\columnwidth]{Knn-0}\end{figure}}
                    \setcounter{i}{1}
                    \setcounter{j}{2}
                    \whiledo{\value{i}<5}
                    {
                        \only<\value{j}>{\begin{figure}\includegraphics[width=\columnwidth]{Knn-\arabic{i}}\end{figure}}
                        \stepcounter{i}
                        \stepcounter{j}
                    }
                    \only<3>{$k = 3 \Rightarrow$ red majority}
                    \only<4>{$k = 5 \Rightarrow$ black majority}
                    \only<5>{$k = 7 \Rightarrow$ red majority}
            \end{columns}
            \addreference{matlab source: \href{https://github.com/alexanderlerch/ACA-Slides/blob/master/matlab/displayKnn.m}{matlab/displayKnn.m}}
        \end{frame}
        \begin{frame}{musical genre classification}{classifier: GMM}
            \vspace{-3mm}
            \begin{itemize}
                \item	\textbf{training}: build model of each class distribution as superposition of Gaussian distributions
                \item<2->	\textbf{classification}: compute output of each Gaussian and select class with highest probability
                    \only<2>{
                        \vspace{-1mm}
                        \figwithmatlab{Gmm}
                        }
                \item<3->	\textbf{classifier data}: per class per Gaussian: $\mu$ and covariance, mixture weight?
            \end{itemize}
        \end{frame}
        \begin{frame}{musical genre classification}{classifier: SVM}
            \begin{itemize}
                \item	\textbf{training}:
                    \begin{itemize}
                        \item   map features to high dimensional space
                            \figwithref{SVM}{\href{https://en.wikipedia.org/wiki/Support\_vector\_machine}{https://en.wikipedia.org/wiki/Support\_vector\_machine}}
                        \item   find separating hyperplane through maximum distance of support vectors (data points)
                    \end{itemize}
                \item<2->	\textbf{classification}: apply feature transform and proceed with 'linear' classification
                \item<3->	\textbf{classifier data}: support vectors, kernel, kernel parameters
            \end{itemize}
        \end{frame}
    
    \section{summary}
        \begin{frame}{summary}{lecture content}
            \begin{itemize}
                \item   \textbf{data-driven approach}
                    \begin{itemize}
                        \item   general systems that learn behavior from data
                        \item   human interaction through
                            \begin{itemize}
                                \item   parametrization and procedures
                                \item   data selection
                            \end{itemize}
                    \end{itemize}
                \bigskip
                \item   \textbf{training \& test set}
                    \begin{enumerate}
                        \item   must not overlap
                        \item   must be representative
                    \end{enumerate}
                \bigskip
                \item   \textbf{fine balance of inputs}
                    \begin{enumerate}
                        \item   number of features
                        \item   classifier complexity
                        \item   amount and variability of data
                    \end{enumerate}
            \end{itemize}
            \inserticon{summary}
        \end{frame}
\end{document}
